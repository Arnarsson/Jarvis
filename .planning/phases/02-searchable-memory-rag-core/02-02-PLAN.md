---
phase: 02-searchable-memory-rag-core
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - server/src/jarvis_server/processing/__init__.py
  - server/src/jarvis_server/processing/ocr.py
  - server/src/jarvis_server/processing/embeddings.py
  - server/pyproject.toml
autonomous: true

must_haves:
  truths:
    - "OCR processor extracts readable text from screenshot images"
    - "Embedding processor generates both dense and sparse vectors"
    - "Models are loaded once and reused across calls"
  artifacts:
    - path: "server/src/jarvis_server/processing/ocr.py"
      provides: "OCR text extraction from images"
      exports: ["OCRProcessor"]
    - path: "server/src/jarvis_server/processing/embeddings.py"
      provides: "Dense and sparse embedding generation"
      exports: ["EmbeddingProcessor", "EmbeddingResult"]
    - path: "server/pyproject.toml"
      provides: "New dependencies"
      contains: "easyocr"
  key_links:
    - from: "server/src/jarvis_server/processing/ocr.py"
      to: "easyocr.Reader"
      via: "model initialization"
      pattern: "Reader.*gpu"
    - from: "server/src/jarvis_server/processing/embeddings.py"
      to: "fastembed"
      via: "TextEmbedding and SparseTextEmbedding"
      pattern: "TextEmbedding.*bge-small"
---

<objective>
Create OCR and embedding processing modules with EasyOCR and FastEmbed.

Purpose: Core processing capabilities for the RAG pipeline. OCR extracts searchable text from screenshots, embeddings enable semantic search.

Output: OCRProcessor class for text extraction, EmbeddingProcessor class generating dense (384-dim) + sparse vectors, proper dependency installation.
</objective>

<execution_context>
@/home/sven/.claude/get-shit-done/workflows/execute-plan.md
@/home/sven/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-searchable-memory-rag-core/02-RESEARCH.md

# Existing server structure
@server/pyproject.toml
@server/src/jarvis_server/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add processing dependencies</name>
  <files>server/pyproject.toml</files>
  <action>
Add new dependencies to server/pyproject.toml under [project.dependencies]:

```toml
"easyocr>=1.7",
"fastembed>=0.4",
"arq>=0.26",
"redis>=5.0",
"orjson>=3.9",
"python-dateutil>=2.8",
"pillow>=10.0",
```

These provide:
- easyocr: GPU-accelerated OCR for screenshots
- fastembed: Lightweight embeddings (dense + sparse) without PyTorch bloat
- arq: Async Redis Queue for background jobs
- redis: ARQ's backend
- orjson: Fast JSON parsing for chat exports
- python-dateutil: Date parsing for imports
- pillow: Image preprocessing

After editing, run `pip install -e .` in server/.venv to install dependencies.
  </action>
  <verify>
Run `pip list | grep -E "easyocr|fastembed|arq"` in server/.venv - all three should appear.
  </verify>
  <done>Processing dependencies installed: easyocr, fastembed, arq, redis, orjson, python-dateutil, pillow.</done>
</task>

<task type="auto">
  <name>Task 2: Create OCR processor module</name>
  <files>
server/src/jarvis_server/processing/__init__.py
server/src/jarvis_server/processing/ocr.py
  </files>
  <action>
Create processing/ module with OCR wrapper.

**server/src/jarvis_server/processing/__init__.py:**
```python
from .ocr import OCRProcessor
from .embeddings import EmbeddingProcessor, EmbeddingResult

__all__ = ["OCRProcessor", "EmbeddingProcessor", "EmbeddingResult"]
```

**server/src/jarvis_server/processing/ocr.py:**
Create OCRProcessor class following research patterns:

```python
import easyocr
from PIL import Image
import numpy as np
from functools import lru_cache
import logging

logger = logging.getLogger(__name__)

class OCRProcessor:
    """EasyOCR wrapper for screenshot text extraction."""

    def __init__(self, gpu: bool = True, languages: list[str] | None = None):
        self.languages = languages or ["en"]
        self.gpu = gpu
        self._reader: easyocr.Reader | None = None

    @property
    def reader(self) -> easyocr.Reader:
        """Lazy initialization of EasyOCR reader (5-10s startup)."""
        if self._reader is None:
            logger.info(f"Initializing EasyOCR reader (gpu={self.gpu})")
            self._reader = easyocr.Reader(
                self.languages,
                gpu=self.gpu,
            )
        return self._reader

    def preprocess(self, image: Image.Image) -> np.ndarray:
        """Preprocess image for better OCR accuracy."""
        if image.mode != "RGB":
            image = image.convert("RGB")

        # Resize if too large
        max_dim = 2000
        if max(image.size) > max_dim:
            ratio = max_dim / max(image.size)
            new_size = (int(image.width * ratio), int(image.height * ratio))
            image = image.resize(new_size, Image.LANCZOS)

        return np.array(image)

    def extract_text(self, filepath: str) -> str:
        """Extract text from image file."""
        image = Image.open(filepath)
        img_array = self.preprocess(image)

        results = self.reader.readtext(
            img_array,
            detail=0,  # Return just text, not bounding boxes
            paragraph=True,  # Group into paragraphs
        )

        return "\n".join(results)


@lru_cache(maxsize=1)
def get_ocr_processor() -> OCRProcessor:
    """Get singleton OCR processor instance."""
    return OCRProcessor(gpu=True)
```

Key design choices:
- Lazy reader initialization (avoid 5-10s startup delay on import)
- Singleton pattern with lru_cache (matches existing codebase patterns)
- Preprocess handles non-RGB and oversized images
- paragraph=True groups related text for better context
  </action>
  <verify>
Run `python -c "from jarvis_server.processing.ocr import OCRProcessor; print('OCR import OK')"` in server/.venv.
Note: Don't instantiate - reader init downloads models.
  </verify>
  <done>OCRProcessor created with lazy EasyOCR initialization, image preprocessing, and singleton accessor.</done>
</task>

<task type="auto">
  <name>Task 3: Create embedding processor module</name>
  <files>server/src/jarvis_server/processing/embeddings.py</files>
  <action>
Create EmbeddingProcessor for dense + sparse embeddings.

**server/src/jarvis_server/processing/embeddings.py:**
```python
from dataclasses import dataclass
from functools import lru_cache
import numpy as np
from fastembed import TextEmbedding, SparseTextEmbedding
import logging

logger = logging.getLogger(__name__)


@dataclass
class EmbeddingResult:
    """Result of embedding generation."""
    dense: np.ndarray  # 384-dim dense vector
    sparse_indices: list[int]
    sparse_values: list[float]


class EmbeddingProcessor:
    """FastEmbed wrapper for dense + sparse embeddings."""

    # Model names (constant for hybrid search compatibility)
    DENSE_MODEL = "BAAI/bge-small-en-v1.5"  # 384 dimensions
    SPARSE_MODEL = "prithivida/Splade_PP_en_v1"

    def __init__(self, cache_dir: str | None = None):
        self.cache_dir = cache_dir or "/data/models/fastembed"
        self._dense_model: TextEmbedding | None = None
        self._sparse_model: SparseTextEmbedding | None = None

    @property
    def dense_model(self) -> TextEmbedding:
        """Lazy initialization of dense embedding model."""
        if self._dense_model is None:
            logger.info(f"Loading dense model: {self.DENSE_MODEL}")
            self._dense_model = TextEmbedding(
                model_name=self.DENSE_MODEL,
                cache_dir=self.cache_dir,
            )
        return self._dense_model

    @property
    def sparse_model(self) -> SparseTextEmbedding:
        """Lazy initialization of sparse embedding model."""
        if self._sparse_model is None:
            logger.info(f"Loading sparse model: {self.SPARSE_MODEL}")
            self._sparse_model = SparseTextEmbedding(
                model_name=self.SPARSE_MODEL,
                cache_dir=self.cache_dir,
            )
        return self._sparse_model

    def embed(self, text: str) -> EmbeddingResult:
        """Generate both dense and sparse embeddings for text."""
        # Dense embedding (384-dim)
        dense_list = list(self.dense_model.embed([text]))
        dense_vec = dense_list[0]

        # Sparse embedding (SPLADE)
        sparse_list = list(self.sparse_model.embed([text]))
        sparse_vec = sparse_list[0]

        return EmbeddingResult(
            dense=dense_vec,
            sparse_indices=sparse_vec.indices.tolist(),
            sparse_values=sparse_vec.values.tolist(),
        )

    def embed_batch(self, texts: list[str]) -> list[EmbeddingResult]:
        """Generate embeddings for multiple texts."""
        if not texts:
            return []

        dense_vecs = list(self.dense_model.embed(texts))
        sparse_vecs = list(self.sparse_model.embed(texts))

        return [
            EmbeddingResult(
                dense=dense,
                sparse_indices=sparse.indices.tolist(),
                sparse_values=sparse.values.tolist(),
            )
            for dense, sparse in zip(dense_vecs, sparse_vecs)
        ]


@lru_cache(maxsize=1)
def get_embedding_processor() -> EmbeddingProcessor:
    """Get singleton embedding processor instance."""
    return EmbeddingProcessor()
```

Key design choices:
- BAAI/bge-small-en-v1.5 for dense (384-dim, fast, good quality)
- SPLADE for sparse (learned sparse, better than TF-IDF)
- Lazy model loading (models are large, delay until needed)
- Batch embedding method for efficiency
- Singleton pattern matching codebase conventions
  </action>
  <verify>
Run `python -c "from jarvis_server.processing.embeddings import EmbeddingProcessor, EmbeddingResult; print('Embeddings import OK')"` in server/.venv.
  </verify>
  <done>EmbeddingProcessor created with lazy FastEmbed initialization, dense (bge-small-en-v1.5) + sparse (SPLADE) embedding, batch support.</done>
</task>

</tasks>

<verification>
1. `pip list | grep -E "easyocr|fastembed|arq"` shows all installed
2. `python -c "from jarvis_server.processing import OCRProcessor, EmbeddingProcessor, EmbeddingResult"`
3. Module structure: `ls server/src/jarvis_server/processing/` shows __init__.py, ocr.py, embeddings.py
</verification>

<success_criteria>
- All processing dependencies installed (easyocr, fastembed, arq, redis, orjson, python-dateutil, pillow)
- OCRProcessor with lazy EasyOCR initialization and image preprocessing
- EmbeddingProcessor with lazy FastEmbed initialization for dense + sparse vectors
- Singleton accessors following existing lru_cache pattern
- All imports work without instantiating (models download on first use)
</success_criteria>

<output>
After completion, create `.planning/phases/02-searchable-memory-rag-core/02-02-SUMMARY.md`
</output>
