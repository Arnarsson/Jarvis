---
phase: 04-calendar-meeting-intelligence
plan: 05
type: execute
wave: 3
depends_on: [04-03]
files_modified:
  - agent/pyproject.toml
  - agent/src/jarvis/meeting/recorder.py
  - agent/src/jarvis/meeting/detector.py
  - server/src/jarvis_server/api/meetings.py
autonomous: true
user_setup:
  - service: audio
    why: "Meeting audio capture requires user consent"
    dashboard_config:
      - task: "Verify audio device selection"
        location: "System audio settings"

must_haves:
  truths:
    - "Audio recording requires explicit user consent before starting"
    - "Audio is captured from configured input device"
    - "Recording stops when meeting ends"
    - "Audio files are saved with meeting association"
  artifacts:
    - path: "agent/src/jarvis/meeting/recorder.py"
      provides: "Audio recording with consent gate"
      contains: "MeetingRecorder"
    - path: "server/src/jarvis_server/api/meetings.py"
      provides: "Audio upload endpoint"
      contains: "upload_audio"
  key_links:
    - from: "agent/src/jarvis/meeting/recorder.py"
      to: "sounddevice"
      via: "Audio capture"
      pattern: "import sounddevice"
    - from: "agent/src/jarvis/meeting/recorder.py"
      to: "agent/src/jarvis/meeting/detector.py"
      via: "Integration with meeting state"
      pattern: "MeetingState"
---

<objective>
Implement meeting audio capture with user consent

Purpose: Enable recording of meeting audio when the user provides consent. Audio files are captured on the agent and uploaded to the server for transcription. This fulfills CAL-04 requirement.

Output: Audio recording module in agent, upload API on server
</objective>

<execution_context>
@/home/sven/.claude/get-shit-done/workflows/execute-plan.md
@/home/sven/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-calendar-meeting-intelligence/04-RESEARCH.md
@.planning/phases/04-calendar-meeting-intelligence/04-03-SUMMARY.md
@agent/src/jarvis/meeting/detector.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add audio capture dependencies to agent</name>
  <files>agent/pyproject.toml</files>
  <action>
Add python-sounddevice and scipy to agent dependencies for audio capture.

Update agent/pyproject.toml dependencies:
"python-sounddevice>=0.5.0",
"scipy>=1.14.0",
"numpy>=1.26.0",  # May already exist

These libraries provide:
- sounddevice: Cross-platform audio capture (PipeWire/PulseAudio compatible)
- scipy: WAV file writing
- numpy: Audio data handling
  </action>
  <verify>
cd /home/sven/Documents/jarvis && pip install -e agent/ && python -c "import sounddevice; import scipy.io.wavfile; print('Audio libraries installed')"
  </verify>
  <done>Audio capture dependencies installed</done>
</task>

<task type="auto">
  <name>Task 2: Create meeting recorder module with consent gate</name>
  <files>agent/src/jarvis/meeting/recorder.py</files>
  <action>
Create the audio recording module with consent management.

agent/src/jarvis/meeting/recorder.py:

import os
import secrets
from datetime import datetime, timezone
from pathlib import Path
from typing import Optional
import numpy as np
import sounddevice as sd
from scipy.io import wavfile
import structlog

logger = structlog.get_logger()

class ConsentToken:
    """Represents user consent for audio recording."""
    def __init__(self, meeting_id: str):
        self.meeting_id = meeting_id
        self.token = secrets.token_urlsafe(16)
        self.created_at = datetime.now(timezone.utc)
        self.valid = True

    def revoke(self):
        self.valid = False

class MeetingRecorder:
    """Records meeting audio with consent verification."""

    def __init__(
        self,
        sample_rate: int = 16000,
        channels: int = 1,
        data_dir: Optional[Path] = None
    ):
        self.sample_rate = sample_rate
        self.channels = channels
        self.data_dir = data_dir or Path(os.getenv("JARVIS_DATA_DIR", "/tmp/jarvis")) / "meetings" / "audio"
        self.data_dir.mkdir(parents=True, exist_ok=True)

        self._recording = False
        self._stream: Optional[sd.InputStream] = None
        self._frames: list[np.ndarray] = []
        self._consent_token: Optional[ConsentToken] = None
        self._current_meeting_id: Optional[str] = None

    @property
    def is_recording(self) -> bool:
        return self._recording

    @property
    def has_consent(self) -> bool:
        return self._consent_token is not None and self._consent_token.valid

    def request_consent(self, meeting_id: str) -> ConsentToken:
        """
        Create a consent token for recording.

        The user must explicitly provide this token to start recording.
        This ensures recording only happens with explicit user action.
        """
        token = ConsentToken(meeting_id)
        logger.info(
            "recording_consent_requested",
            meeting_id=meeting_id,
            token=token.token[:8] + "..."
        )
        return token

    def start_recording(self, consent_token: ConsentToken) -> bool:
        """
        Start audio recording with verified consent.

        Args:
            consent_token: Token from request_consent - proves user consented

        Returns:
            True if recording started, False if consent invalid or already recording
        """
        if self._recording:
            logger.warning("recording_already_active")
            return False

        if not consent_token.valid:
            logger.warning("recording_consent_invalid")
            return False

        self._consent_token = consent_token
        self._current_meeting_id = consent_token.meeting_id
        self._frames = []
        self._recording = True

        def audio_callback(indata: np.ndarray, frames: int, time_info, status):
            if status:
                logger.warning("audio_status", status=str(status))
            if self._recording:
                self._frames.append(indata.copy())

        try:
            self._stream = sd.InputStream(
                samplerate=self.sample_rate,
                channels=self.channels,
                dtype=np.float32,
                callback=audio_callback
            )
            self._stream.start()
            logger.info(
                "recording_started",
                meeting_id=self._current_meeting_id,
                sample_rate=self.sample_rate
            )
            return True

        except Exception as e:
            logger.error("recording_start_failed", error=str(e))
            self._recording = False
            return False

    def stop_recording(self) -> Optional[Path]:
        """
        Stop recording and save audio to file.

        Returns:
            Path to saved audio file, or None if no recording
        """
        if not self._recording:
            return None

        self._recording = False

        if self._stream:
            self._stream.stop()
            self._stream.close()
            self._stream = None

        if not self._frames:
            logger.warning("recording_stopped_no_audio")
            return None

        # Concatenate frames
        audio_data = np.concatenate(self._frames, axis=0)

        # Convert to int16 for WAV
        audio_int16 = (audio_data * 32767).astype(np.int16)

        # Save to file
        timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
        filename = f"meeting_{self._current_meeting_id}_{timestamp}.wav"
        filepath = self.data_dir / filename

        wavfile.write(str(filepath), self.sample_rate, audio_int16)

        duration = len(audio_data) / self.sample_rate
        logger.info(
            "recording_saved",
            meeting_id=self._current_meeting_id,
            filepath=str(filepath),
            duration_seconds=round(duration, 2),
            file_size=filepath.stat().st_size
        )

        # Revoke consent token
        if self._consent_token:
            self._consent_token.revoke()
            self._consent_token = None

        self._current_meeting_id = None
        self._frames = []

        return filepath

    def get_audio_devices(self) -> list[dict]:
        """List available audio input devices."""
        devices = sd.query_devices()
        input_devices = []
        for i, d in enumerate(devices):
            if d['max_input_channels'] > 0:
                input_devices.append({
                    'index': i,
                    'name': d['name'],
                    'channels': d['max_input_channels'],
                    'sample_rate': d['default_samplerate'],
                    'is_default': i == sd.default.device[0]
                })
        return input_devices

    def set_device(self, device_index: int) -> None:
        """Set the audio input device to use."""
        sd.default.device = (device_index, None)
        logger.info("audio_device_set", device_index=device_index)
  </action>
  <verify>
python -c "
from jarvis.meeting.recorder import MeetingRecorder, ConsentToken

recorder = MeetingRecorder()
print(f'Recorder initialized, data_dir: {recorder.data_dir}')
print(f'Is recording: {recorder.is_recording}')
print(f'Has consent: {recorder.has_consent}')

# Test consent flow
token = recorder.request_consent('test-meeting-123')
print(f'Consent token created: {token.token[:8]}...')
assert token.valid, 'Token should be valid'

# List devices
devices = recorder.get_audio_devices()
print(f'Found {len(devices)} input devices')
for d in devices[:3]:
    print(f'  - {d[\"name\"]} (default: {d[\"is_default\"]})')

print('MeetingRecorder verified')
"
  </verify>
  <done>Meeting recorder with consent gate implemented</done>
</task>

<task type="auto">
  <name>Task 3: Add audio upload endpoint to server</name>
  <files>server/src/jarvis_server/api/meetings.py</files>
  <action>
Add endpoint for uploading meeting audio files.

Add to server/src/jarvis_server/api/meetings.py:

from fastapi import UploadFile, File
import aiofiles

AUDIO_STORAGE_PATH = Path(os.getenv("JARVIS_DATA_DIR", "/data")) / "meetings" / "audio"
AUDIO_STORAGE_PATH.mkdir(parents=True, exist_ok=True)

class AudioUploadResponse(BaseModel):
    meeting_id: str
    audio_path: str
    file_size: int
    queued_for_transcription: bool

@router.post("/audio/{meeting_id}", response_model=AudioUploadResponse)
async def upload_audio(
    meeting_id: str,
    file: UploadFile = File(...),
    db: AsyncSession = Depends(get_db_session)
) -> AudioUploadResponse:
    """
    Upload meeting audio file for transcription.

    Args:
        meeting_id: The meeting to associate audio with
        file: WAV audio file
    """
    # Verify meeting exists
    result = await db.execute(
        select(Meeting).where(Meeting.id == meeting_id)
    )
    meeting = result.scalar_one_or_none()
    if not meeting:
        raise HTTPException(status_code=404, detail="Meeting not found")

    # Verify consent was given
    if not meeting.consent_given:
        raise HTTPException(status_code=403, detail="Recording consent not recorded for this meeting")

    # Validate file type
    if not file.filename.endswith('.wav'):
        raise HTTPException(status_code=400, detail="Only WAV files accepted")

    # Save file
    timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
    filename = f"meeting_{meeting_id}_{timestamp}.wav"
    filepath = AUDIO_STORAGE_PATH / filename

    async with aiofiles.open(filepath, 'wb') as f:
        content = await file.read()
        await f.write(content)

    file_size = filepath.stat().st_size

    # Update meeting record
    meeting.audio_path = str(filepath)
    meeting.transcript_status = "pending"
    await db.commit()

    # Queue transcription task
    from jarvis_server.processing.tasks import get_arq_pool
    try:
        pool = await get_arq_pool()
        await pool.enqueue_job("transcribe_meeting_task", meeting_id)
        queued = True
    except Exception as e:
        logger.warning("transcription_queue_failed", meeting_id=meeting_id, error=str(e))
        queued = False

    logger.info(
        "audio_uploaded",
        meeting_id=meeting_id,
        filepath=str(filepath),
        file_size=file_size,
        queued=queued
    )

    return AudioUploadResponse(
        meeting_id=meeting_id,
        audio_path=str(filepath),
        file_size=file_size,
        queued_for_transcription=queued
    )

@router.post("/consent/{meeting_id}")
async def record_consent(
    meeting_id: str,
    db: AsyncSession = Depends(get_db_session)
) -> dict:
    """
    Record that user has consented to audio recording for this meeting.

    This endpoint is called by the agent when user approves recording.
    """
    result = await db.execute(
        select(Meeting).where(Meeting.id == meeting_id)
    )
    meeting = result.scalar_one_or_none()

    if not meeting:
        raise HTTPException(status_code=404, detail="Meeting not found")

    meeting.consent_given = True
    await db.commit()

    logger.info("consent_recorded", meeting_id=meeting_id)

    return {"status": "consent_recorded", "meeting_id": meeting_id}

Add at top:
import os
from pathlib import Path
import aiofiles
  </action>
  <verify>
python -c "
from jarvis_server.api.meetings import router
routes = [r.path for r in router.routes]
print(f'Meeting routes: {routes}')
assert any('audio' in str(r) for r in routes), 'Audio upload endpoint missing'
assert any('consent' in str(r) for r in routes), 'Consent endpoint missing'
print('Audio endpoints verified')
"
  </verify>
  <done>Audio upload and consent endpoints added</done>
</task>

</tasks>

<verification>
1. pip install -e agent/ installs sounddevice and scipy
2. python -c "from jarvis.meeting.recorder import MeetingRecorder" works
3. MeetingRecorder requires consent before recording
4. Audio saved as WAV file
5. Server has POST /api/meetings/audio/{meeting_id} endpoint
6. Server has POST /api/meetings/consent/{meeting_id} endpoint
</verification>

<success_criteria>
- Audio dependencies installed (sounddevice, scipy)
- Recording requires ConsentToken before starting
- Audio captured at 16kHz mono (optimal for speech recognition)
- WAV files saved with meeting ID in filename
- Server upload endpoint validates consent_given
- Audio files stored in JARVIS_DATA_DIR/meetings/audio/
- Transcription task queued after upload
</success_criteria>

<output>
After completion, create `.planning/phases/04-calendar-meeting-intelligence/04-05-SUMMARY.md`
</output>
